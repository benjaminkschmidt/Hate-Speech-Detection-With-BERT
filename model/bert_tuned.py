# -*- coding: utf-8 -*-
"""BERT_Tuned.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_5tqfnotYZPBcvGbvECyNBtbhRNmZWNJ

# Installating the necessary packages
"""

!pip install transformers
!pip install tensorboardx
!pip install simpletransformers

# Commented out IPython magic to ensure Python compatibility.
# %%writefile setup.sh
# 
# git clone https://github.com/NVIDIA/apex
# pip install -v --no-cache-dir --global-option="--cpp_ext" --global-option="--cuda_ext" ./apex

!sh setup.sh

"""# Importing the necessary libraries"""

# Commented out IPython magic to ensure Python compatibility.
try:
#   %tensorflow_version 2.x
  print("Tensorflow Version : " + (tf.__version__))
except Exception:
  print(Exception)
  pass
import tensorflow as tf
import tensorflow_hub as hub
import pandas as pd
from tensorflow.keras import layers
from google.colab import drive
from sklearn.metrics import f1_score, accuracy_score
from sklearn.metrics import confusion_matrix
# Install a Drive FUSE wrapper.
 # https://github.com/astrada/google-drive-ocamlfuse
!apt-get install -y -qq software-properties-common python-software-properties module-init-tools
!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null 
!apt-get update -qq 2>&1 > /dev/null
!apt-get -y install -qq google-drive-ocamlfuse fuse
from google.colab import auth 
auth.authenticate_user()
from oauth2client.client import GoogleCredentials 
creds = GoogleCredentials.get_application_default()
import getpass 
!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL
vcode = getpass.getpass() 
!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}
!mkdir -p drive
!google-drive-ocamlfuse drive
print ('Files in Drive:')
!ls drive/Colab Notebooks
drive.mount('/content/gdrive', force_remount=True)

import re
#clean tweets
def preprocess_text(sen):
    # Removing html tags
    sentence = remove_tags(sen)

    # Remove punctuations and numbers
    sentence = re.sub('[^a-zA-Z]', ' ', sentence)

    # Single character removal
    sentence = re.sub(r"\s+[a-zA-Z]\s+", ' ', sentence)

    # Removing multiple spaces
    sentence = re.sub(r'\s+', ' ', sentence)

    #Remove unwanted white space
    sentence=re.sub(r'[^\w\s]',' ', sentence )
    #remove punctuation
    sentence= re.sub(r'\s\s+', ' ', sentence)
    #all lowercase 
    sentence=sentence.lower()

    return sentence

TAG_RE = re.compile(r'<[^>]+>')
#remove html tags
def remove_tags(text):
    return TAG_RE.sub('', text)

"""# Loading the DataFrame"""

# Load the dataset
from google.colab import drive
#!ls drive/Colab_Notebooks
#df = pd.read_csv("/content/drive/My Drive/Colab_Notebooks/labeled_data.gsheet")
df = pd.DataFrame(pd.read_csv("/content/gdrive/My Drive/Colab Notebooks/labeled_data.csv"))

print(df.columns)

# Extract the tweet and type column
# df = df[["Tweet", "Type"]]
df = df[["tweet", "class"]]

# Convert the tweet column to lowercase
df['tweet'] =  df['tweet'].apply(preprocess_text)
df['tweet'] =  df['tweet'].apply(remove_tags)





y = df['class']
print(df.head())
print(df.shape)
print((df[1].value_counts()))

"""# Forming the Training and Testing Sets"""

from sklearn.model_selection import train_test_split
#Wrapper transformer takes a dataframe where the first column is the test data, the second field is the label
X = df["tweet"]
Y = df["class"]

X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=42)

train_df = pd.DataFrame()
test_df = pd.DataFrame()

# Formation of the Training Dataframe
train_df["text"] = X_train
train_df["label"] = y_train
print(train_df.shape)

# Formation of the Testing Dataframe
test_df["text"] = X_test
test_df["label"] = y_test
print(test_df.shape)

"""# Evaluation on Test Data

# BERT Model Initialization
"""

from simpletransformers.classification import ClassificationModel

# Create a ClassificationModel from simpletransformers (Check what this is)
args = {'reprocess_input_data': True, 
      'overwrite_output_dir': True,
      'num_train_epochs': 30}
model = ClassificationModel('bert', 'bert-base-cased', num_labels=3, args = args) # 3 output labels

"""# Training the Model"""

from sklearn.metrics import f1_score, accuracy_score
from sklearn.metrics import confusion_matrix
model.train_model(train_df)


def f1_multiclass(labels, preds):
    return f1_score(labels, preds, average='micro')

def confusion_matrix_cal(labels, pred):
    return confusion_matrix(labels, pred)

result, model_outputs, wrong_predictions = model.eval_model(test_df, f1=f1_multiclass, acc=accuracy_score, conf_matrix=confusion_matrix_cal)

print("---------- Results ----------")
print(result)
print(model_outputs)
print(wrong_predictions)