{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Word Embeddings.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_viHKGx2eD8s",
        "colab_type": "text"
      },
      "source": [
        "#Import the necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CE0SmAX2eLrq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "1c141ffb-0ae3-4e08-f810-c309a56ce9f1"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import nltk\n",
        "import gensim\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7FnS9VHoeyJS",
        "colab_type": "text"
      },
      "source": [
        "#Create the DataFrame and extract the necessary columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxADiFhbBv0-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "f748aebc-7ebb-4a89-ce74-b5afe8be11cd"
      },
      "source": [
        "df = pd.read_csv(\"/content/gdrive/My Drive/Colab Notebooks/labeled_data.csv\")\n",
        "\n",
        "print(df.columns)\n",
        "\n",
        "# Extract the necessary columns\n",
        "df = df[[\"tweet\", \"class\"]]\n",
        "\n",
        "# Convert the columns to lowercase\n",
        "df['tweet'] = df['tweet'].str.lower()\n",
        "\n",
        "print(df.head(10))\n",
        "print(df.shape)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['Unnamed: 0', 'count', 'hate_speech', 'offensive_language', 'neither',\n",
            "       'class', 'tweet'],\n",
            "      dtype='object')\n",
            "                                               tweet  class\n",
            "0  !!! rt @mayasolovely: as a woman you shouldn't...      2\n",
            "1  !!!!! rt @mleew17: boy dats cold...tyga dwn ba...      1\n",
            "2  !!!!!!! rt @urkindofbrand dawg!!!! rt @80sbaby...      1\n",
            "3  !!!!!!!!! rt @c_g_anderson: @viva_based she lo...      1\n",
            "4  !!!!!!!!!!!!! rt @shenikaroberts: the shit you...      1\n",
            "5  !!!!!!!!!!!!!!!!!!\"@t_madison_x: the shit just...      1\n",
            "6  !!!!!!\"@__brighterdays: i can not just sit up ...      1\n",
            "7  !!!!&#8220;@selfiequeenbri: cause i'm tired of...      1\n",
            "8  \" &amp; you might not get ya bitch back &amp; ...      1\n",
            "9  \" @rhythmixx_ :hobbies include: fighting maria...      1\n",
            "(24783, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZweloK_ue81k",
        "colab_type": "text"
      },
      "source": [
        "#Function to Preprocess the text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTHWwTWlFi6K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "\n",
        "def preprocess_text(sen):\n",
        "    # Removing html tags\n",
        "    sentence = remove_tags(sen)\n",
        "\n",
        "    # Remove punctuations and numbers\n",
        "    sentence = re.sub('[^a-zA-Z]', ' ', sentence)\n",
        "\n",
        "    # Single character removal\n",
        "    sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence)\n",
        "\n",
        "    # Removing multiple spaces\n",
        "    sentence = re.sub(r'\\s+', ' ', sentence)\n",
        "\n",
        "    return sentence\n",
        "\n",
        "TAG_RE = re.compile(r'<[^>]+>')\n",
        "\n",
        "def remove_tags(text):\n",
        "    return TAG_RE.sub('', text)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVJU0MiDfFV9",
        "colab_type": "text"
      },
      "source": [
        "#Preprocess the text and extract the output column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzX1SnPfeYSW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "b49b57f3-09c9-4e99-d8e7-3bc30c7f1cbe"
      },
      "source": [
        "tweets = []\n",
        "sentences = list(df['tweet'])\n",
        "for sen in sentences:\n",
        "    tweets.append(preprocess_text(sen))\n",
        "\n",
        "print(len(tweets))\n",
        "print(tweets[0])\n",
        "\n",
        "y = df['class'].to_list()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "24783\n",
            " rt mayasolovely as woman you shouldn complain about cleaning up your house amp as man you should always take the trash out \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdP6bbWEfPDA",
        "colab_type": "text"
      },
      "source": [
        "#Import the embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKEYB2XKf4Ge",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "7baf97df-57a7-4945-dc01-79386b9f76c3"
      },
      "source": [
        "embeddings_url = \"/content/gdrive/My Drive/Colab Notebooks/GoogleNews-vectors-negative300.bin\"\n",
        "embeddings = gensim.models.KeyedVectors.load_word2vec_format(embeddings_url, binary=True)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebw8caumfV6E",
        "colab_type": "text"
      },
      "source": [
        "#Get the word embeddings of the tweets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDlGrsKufdpO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 901
        },
        "outputId": "eb6a3b5a-31ab-466b-91d5-691684fa4639"
      },
      "source": [
        "# print(embeddings.most_similar('camera', topn = 5))\n",
        "\n",
        "X = []\n",
        "Y = []\n",
        "i = 0\n",
        "\n",
        "for tweet in tweets:\n",
        "  # print(i)\n",
        "  temp = []\n",
        "  tweet_word_list = tweet.split(\" \")\n",
        "  for word in tweet_word_list:\n",
        "    try:\n",
        "      word_vec = embeddings[word] # Check for the presence of the word embedding\n",
        "      temp.append(word_vec)\n",
        "    except:\n",
        "      pass\n",
        "  if(len(temp) != 0): # To avoid Division by zero error\n",
        "    X.append(sum(temp)/len(temp))\n",
        "    Y.append(y[i])\n",
        "  i+=1\n",
        "\n",
        "print(len(X))\n",
        "print(len(X[0]))\n",
        "print(X[0])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "24763\n",
            "300\n",
            "[ 0.05579194  0.06608655  0.03765288  0.09530059 -0.07513718  0.03609212\n",
            "  0.00303214 -0.04977344  0.04857526  0.05521901 -0.01877122 -0.14432925\n",
            "  0.01272728 -0.00946917 -0.08495367  0.03400239  0.03912644  0.0992141\n",
            "  0.02508436 -0.06932286 -0.00030118 -0.00521633  0.0624535   0.00100817\n",
            " -0.01331148  0.01950053 -0.0820763   0.0930263   0.0386378  -0.03642346\n",
            " -0.02860042  0.04071335 -0.06397066 -0.04945156 -0.05108933 -0.04012916\n",
            "  0.07456752 -0.02220517  0.0221049   0.0944708   0.04629008 -0.09641229\n",
            "  0.154355   -0.03235226 -0.06574649 -0.03717259 -0.0878325  -0.01153564\n",
            "  0.00023833 -0.00438045 -0.02029128  0.10078757 -0.02491978  0.02601478\n",
            " -0.02058338 -0.00809878 -0.04917544 -0.03198387  0.0820298  -0.02139718\n",
            "  0.01717413  0.06412978 -0.09806024 -0.08373815  0.0035226  -0.03774007\n",
            " -0.05272856  0.07625907 -0.05965006  0.04248628  0.1466762   0.08230591\n",
            "  0.08786901 -0.00220163 -0.14558338 -0.07003929  0.06448364  0.09080869\n",
            "  0.01023647  0.07209124 -0.00201707 -0.05619449  0.05101376 -0.01851727\n",
            " -0.06166004  0.01866513 -0.0460523   0.14428711  0.04734076  0.04305812\n",
            "  0.02538045  0.05139741 -0.06400989 -0.12240165 -0.04699416 -0.03296698\n",
            "  0.01719012  0.05504499  0.01123628  0.00536528 -0.08223697 -0.07725924\n",
            "  0.03768121 -0.0127251  -0.06070092  0.00698707 -0.01805333 -0.01186671\n",
            "  0.03985959 -0.08459473 -0.08539473 -0.01202393 -0.03466216 -0.03468977\n",
            "  0.05035945  0.02085077  0.04153152 -0.01842099  0.02902085  0.03035482\n",
            " -0.06363641 -0.00086612 -0.09344482  0.06338065  0.00381034  0.00791713\n",
            " -0.07010614 -0.01639048  0.05590094  0.01530529 -0.08242071 -0.15822783\n",
            " -0.08391898  0.02108038 -0.0265067  -0.03540039 -0.02838135  0.00982085\n",
            "  0.02481833  0.0964944   0.09843518 -0.04904974  0.0055077   0.00429571\n",
            " -0.02148147 -0.03361729 -0.03205799 -0.06570289 -0.01052856 -0.00540379\n",
            "  0.11015538 -0.02114723 -0.09408715 -0.02695719 -0.03104655  0.0313926\n",
            " -0.05451312 -0.0442316  -0.04765538  0.03816041 -0.01095     0.12920271\n",
            " -0.01716686  0.05560811  0.02629743 -0.1134382   0.05223737 -0.06412543\n",
            "  0.03964379 -0.02906581 -0.15944998 -0.00659507 -0.01581247 -0.0262502\n",
            " -0.0844356  -0.00247846  0.12453497 -0.05074928 -0.07504418  0.04529045\n",
            " -0.02105277  0.00062052  0.04825846  0.01940337 -0.03579276 -0.03303455\n",
            " -0.06072272  0.07047816  0.07128325  0.05652146  0.03893244  0.06872559\n",
            "  0.01941209  0.05244228  0.00905645  0.01711891 -0.08039057 -0.01482591\n",
            " -0.03837885 -0.11738513 -0.00524684  0.05892363 -0.11971901 -0.04670933\n",
            " -0.02798898  0.02971249 -0.06462933 -0.01129368  0.02692813 -0.03020617\n",
            "  0.02008929  0.0359003  -0.08628191  0.0487482  -0.12362816  0.03002857\n",
            "  0.03702218  0.02143206 -0.14633325  0.01766641 -0.0553647  -0.00185431\n",
            " -0.00614784 -0.07779948  0.07241676 -0.04632278  0.07622419  0.06620643\n",
            " -0.00110881 -0.02924165 -0.00711932 -0.07571266 -0.03683036  0.03094773\n",
            "  0.01405298  0.02568999  0.01751128 -0.04301798  0.04881214  0.01085699\n",
            "  0.05334037 -0.0088501  -0.01211548 -0.12083799 -0.06162044 -0.02234177\n",
            " -0.02238828  0.08714076 -0.06320009 -0.10075487  0.04060291  0.02288528\n",
            "  0.05027989  0.08922178  0.04976691 -0.00453876  0.0268918  -0.00706128\n",
            " -0.0232217  -0.03715588 -0.0086808  -0.00195131 -0.1261742  -0.02742513\n",
            "  0.07445853  0.13942464 -0.06589907  0.02909052 -0.06567383  0.00631278\n",
            " -0.00399344  0.08352806  0.13284738  0.06567383  0.01862835 -0.06344169\n",
            "  0.00891113 -0.12818545 -0.06344459  0.01925514  0.07495117 -0.0458919\n",
            "  0.05450439  0.0960054   0.01471819  0.03818803 -0.06490839 -0.03643036\n",
            "  0.00730805  0.09219215  0.0036701   0.06362189 -0.11640276  0.04447429\n",
            " -0.08303252 -0.03104092 -0.00616964 -0.05696614 -0.02135468  0.02213832]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxaUNCg2i7Da",
        "colab_type": "text"
      },
      "source": [
        "#Form the training and testing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mnMNSioi-3p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "a8819484-08d8-49a9-a8a3-120306249650"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = np.array(X)\n",
        "Y = np.array(Y)\n",
        "print(X.shape)\n",
        "print(Y.shape)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.30, random_state=42)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(24763, 300)\n",
            "(24763,)\n",
            "(17334, 300)\n",
            "(7429, 300)\n",
            "(17334,)\n",
            "(7429,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8YXBxYbKme2K",
        "colab_type": "text"
      },
      "source": [
        "#Initialise and run the different models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGBpFHYPmhsq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "outputId": "b68d1293-3c02-4d57-8e3a-abaabc2bb554"
      },
      "source": [
        "# Import the necessary models\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
        "\n",
        "# -------------------------------------------------- Gaussian Naive Bayes Model --------------------------------------------------\n",
        "\n",
        "# Initialize the model\n",
        "clf_NB = GaussianNB()\n",
        "\n",
        "print(\"\\n------------------------- Running the GaussianNB Model on the Word Vectors data -------------------------\")\n",
        "\n",
        "# Fit the model on the training data\n",
        "clf_NB.fit(X_train, y_train)\n",
        "\n",
        "# Make the predictions\n",
        "y_pred = clf_NB.predict(X_test)\n",
        "\n",
        "# Get the overall model performance metrics on the testing set\n",
        "print(\"---------- Model Performance Metrics with Gaussian Naive Bayes Model ----------\")\n",
        "print(\"Accuracy : \" + str(accuracy_score(y_test, y_pred, )*100))\n",
        "print(\"Precision : \" + str(precision_score(y_test, y_pred, average='macro')*100))\n",
        "print(\"Recall : \" + str(recall_score(y_test, y_pred, average='macro')*100))\n",
        "\n",
        "# Get the confusion matrix\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "\n",
        "# -------------------------------------------------- Linear SVC Model --------------------------------------------------\n",
        "\n",
        "# Initialize the model\n",
        "clf_SVC = SVC(gamma='auto')\n",
        "\n",
        "print(\"\\n------------------------- Running the SVC Model on Word Vectors data -------------------------\")\n",
        "\n",
        "# Fit the model on the training data\n",
        "clf_SVC.fit(X_train, y_train)\n",
        "\n",
        "# Make the predictions\n",
        "y_pred = clf_SVC.predict(X_test)\n",
        "\n",
        "# Get the overall model performance metrics on the testing set\n",
        "print(\"---------- Model Performance Metrics with SVC Model ----------\")\n",
        "print(\"Accuracy : \" + str(accuracy_score(y_test, y_pred, )*100))\n",
        "print(\"Precision : \" + str(precision_score(y_test, y_pred, average='macro')*100))\n",
        "print(\"Recall : \" + str(recall_score(y_test, y_pred, average='macro')*100))\n",
        "\n",
        "# Get the confusion matrix\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "\n",
        "# -------------------------------------------------- Random Forest Model --------------------------------------------------\n",
        "\n",
        "# Initialize the model\n",
        "clf_rf = RandomForestClassifier()\n",
        "\n",
        "print(\"\\n------------------------- Running the Random Forest Model on the Word Vectors data -------------------------\")\n",
        "\n",
        "# Fit the model on the training data\n",
        "clf_rf.fit(X_train, y_train)\n",
        "\n",
        "# Make the predictions\n",
        "y_pred = clf_rf.predict(X_test)\n",
        "\n",
        "# Get the overall model performance metrics on the testing set\n",
        "print(\"---------- Model Performance Metrics with Random Forest Model ----------\")\n",
        "print(\"Accuracy : \" + str(accuracy_score(y_test, y_pred, )*100))\n",
        "print(\"Precision : \" + str(precision_score(y_test, y_pred, average='macro')*100))\n",
        "print(\"Recall : \" + str(recall_score(y_test, y_pred, average='macro')*100))\n",
        "\n",
        "# Get the confusion matrix\n",
        "print(confusion_matrix(y_test, y_pred))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "------------------------- Running the GaussianNB Model on the Word Vectors data -------------------------\n",
            "---------- Model Performance Metrics with Gaussian Naive Bayes Model ----------\n",
            "Accuracy : 69.43060977251312\n",
            "Precision : 50.579158338810494\n",
            "Recall : 57.41516609904006\n",
            "[[ 104  207  132]\n",
            " [ 812 4094  842]\n",
            " [ 142  136  960]]\n",
            "\n",
            "------------------------- Running the SVC Model on Word Vectors data -------------------------\n",
            "---------- Model Performance Metrics with SVC Model ----------\n",
            "Accuracy : 77.77628213756898\n",
            "Precision : 55.63611501111501\n",
            "Recall : 34.20446586464576\n",
            "[[   0  442    1]\n",
            " [   0 5745    3]\n",
            " [   0 1205   33]]\n",
            "\n",
            "------------------------- Running the Random Forest Model on the Word Vectors data -------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "---------- Model Performance Metrics with Random Forest Model ----------\n",
            "Accuracy : 84.82972136222911\n",
            "Precision : 88.8945771605707\n",
            "Recall : 50.540687224440674\n",
            "[[   5  388   50]\n",
            " [   0 5651   97]\n",
            " [   0  592  646]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}